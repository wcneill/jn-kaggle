{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Round 2: Addressing Survival Class Imbalance:\n",
    "Let's take a look at our survival classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.618629\n",
       "1    0.381371\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.utils import io\n",
    "with io.capture_output() as captured:\n",
    "    %run log_reg_01.ipynb\n",
    "\n",
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, passenger death accounts for 61 percent of the classifications. This can cause our model to be biased in that direction. Let's try to address this imbalance with random over-sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.926007e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.470230</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.388379e-16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.502445</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.237127e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.402990</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.816080e-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.486337</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.370406e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.437007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.859368e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.491456</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.784949e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.504962</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-8.059285e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.481304</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.473829e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.496405</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.548247e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.491874</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass  Sex           Age  SibSp  Parch      Fare  Survived\n",
       "PassengerId                                                             \n",
       "294               0    1 -3.926007e-01      1      0 -0.470230         0\n",
       "426               0    0  2.388379e-16      1      0 -0.502445         0\n",
       "499               1    1 -3.237127e-01      0      2  2.402990         0\n",
       "91                0    0 -4.816080e-02      1      0 -0.486337         0\n",
       "227               2    0 -7.370406e-01      1      0 -0.437007         1\n",
       "...             ...  ...           ...    ...    ...       ...       ...\n",
       "147               0    0 -1.859368e-01      1      0 -0.491456         1\n",
       "762               0    0  7.784949e-01      1      0 -0.504962         0\n",
       "835               0    0 -8.059285e-01      1      0 -0.481304         0\n",
       "846               0    0  8.473829e-01      1      0 -0.496405         0\n",
       "163               0    0 -2.548247e-01      1      0 -0.491874         0\n",
       "\n",
       "[569 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join training data together to resample as a whole:\n",
    "xidxs = x_train.index\n",
    "yidxs = y_train.index\n",
    "osample_df = pd.concat([x_train, y_train], axis = 1)\n",
    "osample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(352, 217)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lived = osample_df[osample_df.Survived == 1]\n",
    "df_died = osample_df[osample_df.Survived == 0]\n",
    "\n",
    "# get counts of survivals\n",
    "died, lived = osample_df.Survived.value_counts()\n",
    "died, lived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to oversample the minority class, which is \"survived\"\n",
    "df_lived = df_lived.sample(died, replace=True, random_state=333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the training data back now that it is evenly distributed:\n",
    "osample_df = pd.concat([df_lived, df_died])\n",
    "x_train = osample_df.drop(['Survived'], axis=1)\n",
    "y_train = osample_df.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    352\n",
       "0    352\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show even distribution of survival class\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.530377</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.502445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.571831</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.786845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.254825</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.488854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.365167</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.486337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.674039</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.395814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.770360</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.312172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.770360</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.312172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.949591</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.113846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.640719</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.018709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.081480</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.490280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass  Sex       Age  SibSp  Parch      Fare\n",
       "PassengerId                                               \n",
       "1                 0    0 -0.530377      0      0 -0.502445\n",
       "2                 1    1  0.571831      0      0  0.786845\n",
       "3                 0    1 -0.254825      1      0 -0.488854\n",
       "5                 0    0  0.365167      1      0 -0.486337\n",
       "7                 1    0  1.674039      1      0  0.395814\n",
       "11                0    1 -1.770360      0      1 -0.312172\n",
       "11                0    1 -1.770360      0      1 -0.312172\n",
       "12                1    1  1.949591      1      0 -0.113846\n",
       "14                0    0  0.640719      0      3 -0.018709\n",
       "15                0    1 -1.081480      1      0 -0.490280"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.sort_values(by=\"PassengerId\").head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the results of our oversampling in the duplicate passenger ID 11. We can also check to see if there is an even distribution of Survived classes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's split our data back into independent and dependent variables, train a new model and see how it does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Logistic Regression 1: \n",
      "\t Died: \n",
      "\t\t precision :  0.8085106382978723\n",
      "\t\t recall :  0.8636363636363636\n",
      "\t\t f1-score :  0.8351648351648351\n",
      "\t\t support :  88\n",
      "\t Survived: \n",
      "\t\t precision :  0.7551020408163265\n",
      "\t\t recall :  0.6727272727272727\n",
      "\t\t f1-score :  0.7115384615384616\n",
      "\t\t support :  55\n",
      "\t accuracy :  0.7902097902097902\n",
      "\t macro avg: \n",
      "\t\t precision :  0.7818063395570993\n",
      "\t\t recall :  0.7681818181818182\n",
      "\t\t f1-score :  0.7733516483516483\n",
      "\t\t support :  143\n",
      "\t weighted avg: \n",
      "\t\t precision :  0.7879688700357393\n",
      "\t\t recall :  0.7902097902097902\n",
      "\t\t f1-score :  0.7876162299239222\n",
      "\t\t support :  143\n",
      "\t AUC :  0.8022727272727272\n",
      "\t Classifier :  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "\t Notes :   Minimal Features. No resampling to address class imbalance. No hyper-parameter tuning.\n",
      " Logistic Regression 2: \n",
      "\t Died: \n",
      "\t\t precision :  0.8\n",
      "\t\t recall :  0.7727272727272727\n",
      "\t\t f1-score :  0.7861271676300577\n",
      "\t\t support :  88\n",
      "\t Survived: \n",
      "\t\t precision :  0.6551724137931034\n",
      "\t\t recall :  0.6909090909090909\n",
      "\t\t f1-score :  0.6725663716814159\n",
      "\t\t support :  55\n",
      "\t accuracy :  0.7412587412587412\n",
      "\t macro avg: \n",
      "\t\t precision :  0.7275862068965517\n",
      "\t\t recall :  0.7318181818181818\n",
      "\t\t f1-score :  0.7293467696557367\n",
      "\t\t support :  143\n",
      "\t weighted avg: \n",
      "\t\t precision :  0.7442970822281169\n",
      "\t\t recall :  0.7412587412587412\n",
      "\t\t f1-score :  0.7424499384190416\n",
      "\t\t support :  143\n",
      "\t AUC :  0.8016528925619836\n",
      "\t Classifier :  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "\t Notes :  Minimal Features. Over-sampled to address Surivival class imbalance. No Tuning\n"
     ]
    }
   ],
   "source": [
    "models['Logistic Regression 2'] = evaluate(linear_model.LogisticRegression())\n",
    "models['Logistic Regression 2']['Notes'] = \"Minimal Features. Over-sampled to address Surivival class imbalance. No Tuning\"\n",
    "pprint(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Round 2 Performance:\n",
    "\n",
    "In almost all metrics our score went down by several points. \n",
    "\n",
    "Since over-sampling did not help us out, we need go back up to the initial train/test split cells and start from scratch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
