{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Network for MNIST Predictions. \n",
    "In this notebook, I will be using a convolutional architecture rather than a fully connected network. The architecture I am adopting is LeNet-5, which has recorded an error rate as low as 0.95 (or %99.05 accurate). I don't know if I will get quite those results, but let's try!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn import model_selection\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Dataset Object\n",
    "Since the dataset provided by Kaggle is not in image format, we can define a custom MNIST dataset object in PyTorch. In the Kaggle dataset, each row of the .csv file represents a single image and its label. The first entry in the row is the image label, while the other 784 entries in the row are the unstacked image pixel values. \n",
    "\n",
    "For a convolutional network, we will need to transform those row vectors back into 3D tensors representing actual image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST(Dataset):\n",
    "    def __init__(self, df, labels=True, transform=None):\n",
    "        \n",
    "        self.df = df\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist()\n",
    "   \n",
    "        if self.labels:\n",
    "            label = self.df.iloc[index, 0]\n",
    "            data  = self.df.iloc[index, 1:].to_numpy(np.uint8).reshape(28,28, 1)\n",
    "            if self.transform:\n",
    "                data = self.transform(data)\n",
    "            return data, label\n",
    "    \n",
    "        data  = self.df.iloc[index].to_numpy(dtype=np.uint8).reshape(28,28, 1)\n",
    "        print(type(data))\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "        \n",
    "        return data\n",
    "    \n",
    "class to_dtype(object):\n",
    "    def __call__(self, x, dtype=torch.FloatTensor):\n",
    "        return x.type(dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforms, Datasets and DataLoaders\n",
    "\n",
    "Next, we define very basic transforms. First, we transform each 28x28 numpy array into a 1x28x28 torch image tensor. Then we normalize the data to help convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment = transforms.Compose([transforms.ToPILImage(),\n",
    "                                transforms.RandomRotation(10, fill=(0,)),\n",
    "                                transforms.RandomPerspective(),\n",
    "                                transforms.RandomAffine(10),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "tfs = transforms.Compose([transforms.ToTensor(),\n",
    "                          transforms.Normalize((0.5,), (0.5,))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read in our Kaggle training data, split it (25% validation hold out) and get it into `DataLoaders`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "X, y = train_df.iloc[:, 1:], train_df.iloc[:, 0]\n",
    "x_train, x_valid, y_train, y_valid = model_selection.train_test_split(X, y)\n",
    "\n",
    "trainset = MNIST(pd.concat([y_train, x_train], axis=1), transform=augment)\n",
    "validset = MNIST(pd.concat([y_valid, x_valid], axis=1), transform=tfs)\n",
    "\n",
    "trainload = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=4)\n",
    "validload = DataLoader(validset, batch_size=32, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to make sure that everything is looking good before we get started, let's take a look at a few images:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = iter(validload).next()\n",
    "\n",
    "fig = plt.figure(figsize=(25,4))\n",
    "\n",
    "for i in range(20):\n",
    "    ax = fig.add_subplot(2, 20/2, i+1, xticks=[], yticks=[])\n",
    "    ax.set_title(f'Label: {labels[i].item()}')\n",
    "    ax.imshow(images[i].squeeze())\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "images[0].dtype, images[0].shape, images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(2, stride=2),\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(4*4*16, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.out = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.fc(x)\n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = LeNet()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(model.parameters(), lr=0.0005)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(opt, 'min', patience=7)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "epochs = 30\n",
    "\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "accuracy   = []\n",
    "valid_low = np.Inf\n",
    "\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_tl = 0\n",
    "    running_vl = 0\n",
    "    running_ac = 0\n",
    "    \n",
    "    # backprop and and update\n",
    "    model.train()\n",
    "    for images, labels in trainload:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        opt.zero_grad()\n",
    "        t_cel = criterion(model(images.float()), labels)\n",
    "        t_cel.backward()\n",
    "        opt.step()\n",
    "        running_tl += t_cel.item()\n",
    "        \n",
    "    # validation pass    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for images, labels in validload:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            scores = model(images.float())\n",
    "            ps = F.softmax(scores, dim=1)\n",
    "            v_cel = criterion(scores, labels)\n",
    "            pred = torch.argmax(ps, dim=1)\n",
    "            running_ac += (pred == labels).cpu().numpy().mean()\n",
    "            running_vl += v_cel.item()\n",
    "    \n",
    "    # Decay Learning Rate:\n",
    "    print(f'Epoch {e} Learning Rate: {opt.param_groups[0][\"lr\"]} Validation Loss: {v_cel}')\n",
    "    scheduler.step(v_cel)\n",
    "\n",
    "    # get loss metrics for plotting later\n",
    "    train_loss.append(running_tl/len(trainload))\n",
    "    valid_loss.append(running_vl/len(validload))\n",
    "    accuracy.append(running_ac/len(validload))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Loss vs Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.plot(train_loss, label='Training')\n",
    "plt.plot(valid_loss, label='Validation')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Accuracy on Validation Set by Epoch')\n",
    "plt.xlabel('Epochs')\n",
    "plt.plot(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions of Kaggle Competition Data:\n",
    "Now that we have a model that is doing quite well on validation set, let's put it to the test in our competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_data = pd.read_csv('data/test.csv')\n",
    "comp_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_set = MNIST(comp_data, labels=False, transform=tfs)\n",
    "comp_loader = DataLoader(comp_set, batch_size=32, num_workers=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = iter(comp_loader).next()\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.array([])\n",
    "\n",
    "for images in unk_loader:\n",
    "    images = images.to(device).float()\n",
    "    scores = model(images)\n",
    "    ps = F.softmax(scores, dim=1)\n",
    "    preds = torch.argmax(ps, dim=1).cpu()\n",
    "    predictions = np.append(predictions, preds)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame(\n",
    "    {\n",
    "        'ImageId': np.arange(1, len(predictions) + 1),\n",
    "        'Label': predictions\n",
    "    }\n",
    ")\n",
    "\n",
    "sub_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = iter(unk_loader).next()\n",
    "\n",
    "fig = plt.figure(figsize=(25,4))\n",
    "\n",
    "for i in range(20):\n",
    "    ax = fig.add_subplot(2, 20/2, i+1, xticks=[], yticks=[])\n",
    "    ax.set_title(f'Label: {sub_df.loc[i, \"Label\"]}')\n",
    "    ax.imshow(images[i].squeeze())\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks pretty good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.to_csv('submission_LeNet.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m49",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
