{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Network for MNIST Predictions. \n",
    "In this notebook, I will be using a convolutional architecture rather than a fully connected network. The architecture I am adopting is LeNet-5, which has recorded an error rate as low as 0.95 (or %99.05 accurate). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plot\n",
    "import pandas as pd\n",
    "\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST(Dataset):\n",
    "    def __init__(self, csv_path, transform=None):\n",
    "        self.pixel_frame = pd.read_csv(csv_path)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.pixel_frame)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        label = self.pixel_frame.iloc[index, 0].to_numpy(dtype='float64')\n",
    "        data  = self.pixel_frame.iloc[index, 1:].to_numpy(dtype='float64')\n",
    "        \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "        \n",
    "        return data, label\n",
    "\n",
    "transform = transforms.Compose([transforms.Normalize((0.5), (0.5)),\n",
    "                               transforms.ToTensor()])\n",
    "\n",
    "trainset = MNIST('data/train.csv', transform=transform)\n",
    "testset = MNIST('data/test.csv', transform=transforms.ToTensor())\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=4)\n",
    "testloader  = DataLoader(testset, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 80/20 split for training and validation sets\n",
    "N = len(trainset)\n",
    "split = (N - int(np.floor(N*.2)), int(np.floor(N*.2)))\n",
    "trainset, validset = torch.utils.data.random_split(trainset, split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainload = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=4)\n",
    "validload = DataLoader(validset, batch_size=32, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(2, stride=2),\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(6, 16, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(5*5*16, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.out = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.fc(x)\n",
    "        return self.out(x)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = LeNet()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.SGD(model.parameters(), lr=0.01)\n",
    "criteion = nn.CrossEntropyLoss()\n",
    "epochs = 10\n",
    "\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_tl = 0\n",
    "    running_vl = 0\n",
    "    \n",
    "    # backprop and and update\n",
    "    model.train()\n",
    "    for images, labels in trainload:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        opt.zero_grad()\n",
    "        t_cel = criterion(model(images), labels)\n",
    "        t_cel.backward()\n",
    "        opt.step()\n",
    "\n",
    "        running_tl += t_cel.item()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for images, labels in validload:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            v_cel = criterion(model(images), labels)\n",
    "            running_vl += v_cel.item()\n",
    "        \n",
    "    train_loss.append(running_tl/len(trainload))\n",
    "    valid_loss.append(running_vl/len(trainload))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
